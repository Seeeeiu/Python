{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seeeeiu/Python/blob/master/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "8eteRKNyWbhG"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 1"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nHRxS7w7XhGs"
      },
      "cell_type": "markdown",
      "source": [
        "# **Note: You will find importing data sets much easier if you have a google drive account.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KgALLGo9WbhH"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 5"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wPKeX4LSWbhI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "#from sklearn.model_selection import train_test_split  \n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)  \n",
        "\n",
        "\n",
        "(train_images, y_train), (test_images, y_test) = mnist.load_data()\n",
        "\n",
        "nsamples, nx, ny = train_images.shape\n",
        "X_train = train_images.reshape((nsamples,nx*ny))\n",
        "\n",
        "nsamples, nx, ny = test_images.shape\n",
        "X_test = test_images.reshape((nsamples,nx*ny))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xCmeb3tqWbhM"
      },
      "cell_type": "markdown",
      "source": [
        "###a. "
      ]
    },
    {
      "metadata": {
        "id": "yZC-Fgzib9rL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using a training data set of 42000 observations, transform and fit the training data with 90% of the variance retained. Transform the remaining testing data (do not refit for the second transform)"
      ]
    },
    {
      "metadata": {
        "id": "nzIfrGUC0jzf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images.shape\n",
        "test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RgnrTmudg-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyzLR0m2e5az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0o2UBjs4WbhP"
      },
      "cell_type": "markdown",
      "source": [
        "### b."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m_3st-rVWbhP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UPIrXy-PWbhR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sum(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uxnYXmAyWbhS"
      },
      "cell_type": "markdown",
      "source": [
        "### c."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wjYzNaroWbhT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CKORTPC8WbhV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rjOyhtOHWbhX"
      },
      "cell_type": "markdown",
      "source": [
        "### d."
      ]
    },
    {
      "metadata": {
        "id": "6n-Cx1BzzbYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kEskaLNYWbhY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist(x=y_train, bins='auto', color='#0504aa',\n",
        "                            alpha=0.7, rwidth=0.85)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SAIspfESWbha"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VY7tCQUkWbhb",
        "outputId": "bb4d423a-9fa6-4882-b588-f1abea468ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g27rEueRWbhe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train6 = pd.read_csv('/content/gdrive/My Drive/lab1/train.csv', sep=',', decimal='.')\n",
        "test6 = pd.read_csv('/content/gdrive/My Drive/lab1/test.csv', sep=',', decimal='.')\n",
        "\n",
        "X_train = train6[['ListPrice','Age','Living','Lot']]\n",
        "y_train = train6.iloc[:, 0]\n",
        "X_test = test6.iloc[:, 1:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gcBawHly9mKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn = KNeighborsRegressor(n_neighbors = 3,metric='euclidean',weights='distance')\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred = knn.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGyj-kA0Bqej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/gdrive/My Drive/lab1/Sample submission.csv', sep=',', decimal='.')\n",
        "submission[['SalePrice']]=y_pred\n",
        "df = pd.DataFrame(data=submission)\n",
        "df.to_csv('/content/gdrive/My Drive/lab1/out6.csv',index = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KLfgeW9pWbhg"
      },
      "cell_type": "markdown",
      "source": [
        "My RMSE is: 71009"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "116LGSM9Wbhh"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 7"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6I4rbc3UWbhi"
      },
      "cell_type": "markdown",
      "source": [
        "### a."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fmbWJ8beWbhj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train7 = pd.read_csv('/content/gdrive/My Drive/lab1/rr_train.csv', sep=',', decimal='.')\n",
        "test7 = pd.read_csv('/content/gdrive/My Drive/lab1/rr_test.csv', sep=',', decimal='.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AYoe-IQyWbhk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "y_train =train7.values[:,-1] # take revenue column\n",
        "x_train =train7.values[:,0:37] # \n",
        "\n",
        "x_train = sm.add_constant(x_train) \n",
        "result = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "x_test = test7.values[:,1:38]\n",
        "x_test = sm.add_constant(x_test)\n",
        "\n",
        "y_pred = result.predict(x_test)\n",
        "                                   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tbjvmpWDWbhl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/gdrive/My Drive/lab1/sample_submission.csv', sep=',', decimal='.')\n",
        "submission[['revenue']]=y_pred\n",
        "df = pd.DataFrame(data=submission)\n",
        "df.to_csv('/content/gdrive/My Drive/lab1/out7.csv',index = False)\n",
        "\n",
        "# RMSE :1945645"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YMBwv0i3Wbhm"
      },
      "cell_type": "markdown",
      "source": [
        "My RMSE is:"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PqiC5ZskWbho"
      },
      "cell_type": "markdown",
      "source": [
        "### b."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1jb2A0i8Wbhp",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1115
        },
        "outputId": "490d47eb-70e5-4194-f371-756cfcf8041d"
      },
      "cell_type": "code",
      "source": [
        "result.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.461</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.139</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.430</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 22 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.105</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>20:13:36</td>     <th>  Log-Likelihood:    </th> <td> -1578.5</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   3233.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>   3332.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    37</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td> 6.195e+06</td> <td> 4.39e+06</td> <td>    1.411</td> <td> 0.163</td> <td>-2.58e+06</td> <td>  1.5e+07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td> 2.633e+05</td> <td> 4.19e+05</td> <td>    0.629</td> <td> 0.532</td> <td>-5.74e+05</td> <td>  1.1e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>-2.587e+04</td> <td> 4.13e+05</td> <td>   -0.063</td> <td> 0.950</td> <td>-8.52e+05</td> <td>    8e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>-4.254e+05</td> <td> 4.46e+05</td> <td>   -0.954</td> <td> 0.344</td> <td>-1.32e+06</td> <td> 4.66e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>-4.245e+05</td> <td> 7.02e+05</td> <td>   -0.605</td> <td> 0.548</td> <td>-1.83e+06</td> <td> 9.79e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>-1.362e+05</td> <td> 4.91e+05</td> <td>   -0.277</td> <td> 0.782</td> <td>-1.12e+06</td> <td> 8.45e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td> 9.113e+04</td> <td> 2.41e+05</td> <td>    0.378</td> <td> 0.706</td> <td> -3.9e+05</td> <td> 5.72e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td> 1.734e+05</td> <td> 2.87e+05</td> <td>    0.603</td> <td> 0.548</td> <td>-4.01e+05</td> <td> 7.48e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>-7.392e+05</td> <td> 5.99e+05</td> <td>   -1.234</td> <td> 0.222</td> <td>-1.94e+06</td> <td> 4.58e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td> 7.294e+05</td> <td>  1.2e+06</td> <td>    0.608</td> <td> 0.545</td> <td>-1.67e+06</td> <td> 3.13e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>-1.148e+06</td> <td> 1.82e+06</td> <td>   -0.632</td> <td> 0.530</td> <td>-4.78e+06</td> <td> 2.48e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td> 1.901e+05</td> <td> 3.48e+05</td> <td>    0.546</td> <td> 0.587</td> <td>-5.06e+05</td> <td> 8.87e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td> 5.666e+04</td> <td> 8.41e+05</td> <td>    0.067</td> <td> 0.947</td> <td>-1.63e+06</td> <td> 1.74e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td> 2.067e+05</td> <td> 1.63e+06</td> <td>    0.127</td> <td> 0.899</td> <td>-3.05e+06</td> <td> 3.46e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>-5.603e+05</td> <td> 4.91e+05</td> <td>   -1.142</td> <td> 0.258</td> <td>-1.54e+06</td> <td> 4.21e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td> 1.583e+05</td> <td> 5.79e+05</td> <td>    0.273</td> <td> 0.785</td> <td>-9.99e+05</td> <td> 1.32e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>-8.443e+05</td> <td> 5.97e+05</td> <td>   -1.414</td> <td> 0.162</td> <td>-2.04e+06</td> <td> 3.49e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td> 6.989e+05</td> <td> 4.79e+05</td> <td>    1.458</td> <td> 0.150</td> <td>-2.59e+05</td> <td> 1.66e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td> 1.064e+06</td> <td> 5.48e+05</td> <td>    1.943</td> <td> 0.057</td> <td>-3.07e+04</td> <td> 2.16e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>-1.773e+05</td> <td> 2.09e+05</td> <td>   -0.849</td> <td> 0.399</td> <td>-5.95e+05</td> <td>  2.4e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>-4.783e+05</td> <td> 1.93e+05</td> <td>   -2.481</td> <td> 0.016</td> <td>-8.64e+05</td> <td> -9.3e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td> 8.166e+05</td> <td> 3.95e+05</td> <td>    2.069</td> <td> 0.043</td> <td> 2.77e+04</td> <td> 1.61e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>-6178.4742</td> <td> 3.25e+05</td> <td>   -0.019</td> <td> 0.985</td> <td>-6.56e+05</td> <td> 6.44e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td> 3.923e+04</td> <td> 1.48e+05</td> <td>    0.266</td> <td> 0.791</td> <td>-2.56e+05</td> <td> 3.34e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td> 2.601e+05</td> <td> 6.39e+05</td> <td>    0.407</td> <td> 0.685</td> <td>-1.02e+06</td> <td> 1.54e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td> 8.806e+05</td> <td> 7.11e+05</td> <td>    1.239</td> <td> 0.220</td> <td> -5.4e+05</td> <td>  2.3e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>-1.355e+06</td> <td> 7.56e+05</td> <td>   -1.792</td> <td> 0.078</td> <td>-2.87e+06</td> <td> 1.56e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td> -2.72e+05</td> <td> 2.97e+05</td> <td>   -0.916</td> <td> 0.363</td> <td>-8.65e+05</td> <td> 3.21e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td> 9.618e+05</td> <td> 3.47e+05</td> <td>    2.775</td> <td> 0.007</td> <td> 2.69e+05</td> <td> 1.65e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td> 7.537e+05</td> <td> 4.47e+05</td> <td>    1.687</td> <td> 0.097</td> <td>-1.39e+05</td> <td> 1.65e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x30</th>   <td> 5.258e+05</td> <td> 2.82e+05</td> <td>    1.861</td> <td> 0.067</td> <td>-3.89e+04</td> <td> 1.09e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x31</th>   <td> 8.969e+04</td> <td> 4.73e+05</td> <td>    0.190</td> <td> 0.850</td> <td>-8.55e+05</td> <td> 1.03e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x32</th>   <td> -4.49e+05</td> <td> 5.25e+05</td> <td>   -0.856</td> <td> 0.395</td> <td> -1.5e+06</td> <td>    6e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x33</th>   <td>-7.459e+05</td> <td> 5.56e+05</td> <td>   -1.340</td> <td> 0.185</td> <td>-1.86e+06</td> <td> 3.67e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x34</th>   <td> 6.401e+05</td> <td> 5.06e+05</td> <td>    1.266</td> <td> 0.210</td> <td>-3.71e+05</td> <td> 1.65e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x35</th>   <td>-1.715e+05</td> <td> 4.45e+05</td> <td>   -0.386</td> <td> 0.701</td> <td>-1.06e+06</td> <td> 7.18e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x36</th>   <td>-8.498e+05</td> <td> 1.14e+06</td> <td>   -0.746</td> <td> 0.459</td> <td>-3.13e+06</td> <td> 1.43e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x37</th>   <td> 9.788e+05</td> <td>  5.2e+05</td> <td>    1.884</td> <td> 0.064</td> <td>-5.97e+04</td> <td> 2.02e+06</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>38.010</td> <th>  Durbin-Watson:     </th> <td>   1.674</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  93.314</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 1.395</td> <th>  Prob(JB):          </th> <td>5.46e-21</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 6.823</td> <th>  Cond. No.          </th> <td>    528.</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.461\n",
              "Model:                            OLS   Adj. R-squared:                  0.139\n",
              "Method:                 Least Squares   F-statistic:                     1.430\n",
              "Date:                Tue, 22 Jan 2019   Prob (F-statistic):              0.105\n",
              "Time:                        20:13:36   Log-Likelihood:                -1578.5\n",
              "No. Observations:                 100   AIC:                             3233.\n",
              "Df Residuals:                      62   BIC:                             3332.\n",
              "Df Model:                          37                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const       6.195e+06   4.39e+06      1.411      0.163   -2.58e+06     1.5e+07\n",
              "x1          2.633e+05   4.19e+05      0.629      0.532   -5.74e+05     1.1e+06\n",
              "x2         -2.587e+04   4.13e+05     -0.063      0.950   -8.52e+05       8e+05\n",
              "x3         -4.254e+05   4.46e+05     -0.954      0.344   -1.32e+06    4.66e+05\n",
              "x4         -4.245e+05   7.02e+05     -0.605      0.548   -1.83e+06    9.79e+05\n",
              "x5         -1.362e+05   4.91e+05     -0.277      0.782   -1.12e+06    8.45e+05\n",
              "x6          9.113e+04   2.41e+05      0.378      0.706    -3.9e+05    5.72e+05\n",
              "x7          1.734e+05   2.87e+05      0.603      0.548   -4.01e+05    7.48e+05\n",
              "x8         -7.392e+05   5.99e+05     -1.234      0.222   -1.94e+06    4.58e+05\n",
              "x9          7.294e+05    1.2e+06      0.608      0.545   -1.67e+06    3.13e+06\n",
              "x10        -1.148e+06   1.82e+06     -0.632      0.530   -4.78e+06    2.48e+06\n",
              "x11         1.901e+05   3.48e+05      0.546      0.587   -5.06e+05    8.87e+05\n",
              "x12         5.666e+04   8.41e+05      0.067      0.947   -1.63e+06    1.74e+06\n",
              "x13         2.067e+05   1.63e+06      0.127      0.899   -3.05e+06    3.46e+06\n",
              "x14        -5.603e+05   4.91e+05     -1.142      0.258   -1.54e+06    4.21e+05\n",
              "x15         1.583e+05   5.79e+05      0.273      0.785   -9.99e+05    1.32e+06\n",
              "x16        -8.443e+05   5.97e+05     -1.414      0.162   -2.04e+06    3.49e+05\n",
              "x17         6.989e+05   4.79e+05      1.458      0.150   -2.59e+05    1.66e+06\n",
              "x18         1.064e+06   5.48e+05      1.943      0.057   -3.07e+04    2.16e+06\n",
              "x19        -1.773e+05   2.09e+05     -0.849      0.399   -5.95e+05     2.4e+05\n",
              "x20        -4.783e+05   1.93e+05     -2.481      0.016   -8.64e+05    -9.3e+04\n",
              "x21         8.166e+05   3.95e+05      2.069      0.043    2.77e+04    1.61e+06\n",
              "x22        -6178.4742   3.25e+05     -0.019      0.985   -6.56e+05    6.44e+05\n",
              "x23         3.923e+04   1.48e+05      0.266      0.791   -2.56e+05    3.34e+05\n",
              "x24         2.601e+05   6.39e+05      0.407      0.685   -1.02e+06    1.54e+06\n",
              "x25         8.806e+05   7.11e+05      1.239      0.220    -5.4e+05     2.3e+06\n",
              "x26        -1.355e+06   7.56e+05     -1.792      0.078   -2.87e+06    1.56e+05\n",
              "x27         -2.72e+05   2.97e+05     -0.916      0.363   -8.65e+05    3.21e+05\n",
              "x28         9.618e+05   3.47e+05      2.775      0.007    2.69e+05    1.65e+06\n",
              "x29         7.537e+05   4.47e+05      1.687      0.097   -1.39e+05    1.65e+06\n",
              "x30         5.258e+05   2.82e+05      1.861      0.067   -3.89e+04    1.09e+06\n",
              "x31         8.969e+04   4.73e+05      0.190      0.850   -8.55e+05    1.03e+06\n",
              "x32         -4.49e+05   5.25e+05     -0.856      0.395    -1.5e+06       6e+05\n",
              "x33        -7.459e+05   5.56e+05     -1.340      0.185   -1.86e+06    3.67e+05\n",
              "x34         6.401e+05   5.06e+05      1.266      0.210   -3.71e+05    1.65e+06\n",
              "x35        -1.715e+05   4.45e+05     -0.386      0.701   -1.06e+06    7.18e+05\n",
              "x36        -8.498e+05   1.14e+06     -0.746      0.459   -3.13e+06    1.43e+06\n",
              "x37         9.788e+05    5.2e+05      1.884      0.064   -5.97e+04    2.02e+06\n",
              "==============================================================================\n",
              "Omnibus:                       38.010   Durbin-Watson:                   1.674\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               93.314\n",
              "Skew:                           1.395   Prob(JB):                     5.46e-21\n",
              "Kurtosis:                       6.823   Cond. No.                         528.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}